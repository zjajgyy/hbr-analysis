package com.xiang

import kafka.serializer.StringDecoder
import net.sf.json.JSONObject
import org.apache.spark.SparkConf
import org.apache.spark.streaming.kafka.KafkaUtils
import org.apache.spark.streaming.{Seconds, StreamingContext}

import scala.collection.mutable.ArrayBuffer

/**
  * Created by hmh on 2016/12/25.*/
object PageViewStream {

  val MIN = 0.3
  val MAX = 2
  val TIME_INTERVAL = 0.004

  def getInterval(arrayBuffer: ArrayBuffer[Int]):ArrayBuffer[Double]={
    /**
      * 算法开始，第一遍取峰值
      */
    var dataSet = arrayBuffer
    var data_mean = 0
    var data_total = 0
    //申明不定长数组
    var data_1 = new ArrayBuffer[Int]()
    var index_1 = new ArrayBuffer[Int]()
    var id = 0

    for(i <- 0 until dataSet.size){
      data_total = data_total + dataSet(i)
    }
    data_mean = data_total/dataSet.size

    if(dataSet(0) > dataSet(1) && dataSet(0) > data_mean){
      index_1(id) = 0
      data_1(id) = dataSet(0)
      id = id + 1
    }

    var begin_total = 0
    var end_total = 0
    for(j <- 0 until dataSet.size){
      begin_total = begin_total + dataSet(j)
    }

    for(j <- (dataSet.length-499) until dataSet.size){
      end_total = end_total + dataSet(j)
    }
    var mean_begin = begin_total/500
    var mean_end = end_total/500
    for(i <- 1 to dataSet.length - 2){

      //前500个
      if(i < 500){
        if(dataSet(i) > dataSet(i-1) & dataSet(i) > dataSet(i+1) & dataSet(i) > mean_begin){
          println("id:",id)
          data_1 += dataSet(i)
          index_1 += i
          id = id + 1

        }
      }


      //中间段数据
      if(i >= 500 && i <= dataSet.length -500){
        var middle_total = 0
        for(j <- (i-500) to (i+499)){
          middle_total = middle_total + dataSet(j)
        }
        var mean_middle = middle_total/1000
        if(dataSet(i) > dataSet(i-1) && dataSet(i) > dataSet(i+1) && dataSet(i) > mean_middle){
          println("id:",id)
          data_1 += dataSet(i)
          index_1 += i
          id = id + 1
        }
      }

      //后500个
      if(i > dataSet.length - 500){

        if(dataSet(i) > dataSet(i-1) && dataSet(i) > dataSet(i+1) && dataSet(i) > mean_end){
          println("id:",id)
          data_1 += dataSet(i)
          index_1 += i
          id = id + 1
        }
      }
    }

    if(dataSet(dataSet.length-1) > dataSet(dataSet.length - 2) && dataSet(dataSet.length - 1) > data_mean){
      index_1 += dataSet.length - 1
      data_1 += dataSet(dataSet.length-1)
    }


    /**
      * 第二次取峰值
      */
    var data_mean_1 = 0
    var data_total_1 = 0
    //申明不定长数组
    var data_2 = new ArrayBuffer[Int]()
    var index_2 = new ArrayBuffer[Int]()
    var id2 = 0
    println("data_1.length:",data_1.length)
    for(i <- 0 to data_1.length-1){
      data_total_1 = data_total_1 + data_1(i)
    }
    data_mean_1 = data_total_1/data_1.length

    if(data_1(0) > data_1(1) && data_1(0) > data_mean_1){
      index_2(id2) = 0
      data_2(id2) = data_1(0)
      id2 = id2 + 1
    }

    var begin_total_1 = 0
    var end_total_1 = 0
    for(j <- 0 to 199){
      begin_total_1 = begin_total_1 + data_1(j)
    }

    for(j <- (data_1.length-199) to (data_1.length -1) ){
      end_total_1 = end_total_1 + data_1(j)
    }
    var mean_begin_1 = begin_total_1/200
    var mean_end_1 = end_total_1/200

    for(i <- 1 to data_1.length - 2){
      //前200个
      if(i < 200){
        if(dataSet(i) > dataSet(i-1) && dataSet(i) > dataSet(i+1) && dataSet(i) > mean_begin_1){
          index_2(id2) = index_1(i)
          data_2(id2) = data_1(i)
          id2 = id2 + 1
        }
      }

      if(i >= 200 && i <= data_1.length -200){
        var middle_total_1 = 0
        for(j <- (i-200) to (i+199)){
          middle_total_1 = middle_total_1 + data_1(j)
        }
        var mean_middle_1 = middle_total_1/400
        if(dataSet(i) > dataSet(i-1) && dataSet(i) > dataSet(i+1) && dataSet(i) > mean_middle_1){
          index_2(id2) = index_1(i)
          data_2(id2) = data_1(i)
          id2 = id2 + 1
        }
      }

      if(i > data_1.length - 200){
        if(dataSet(i) > dataSet(i-1) && dataSet(i) > dataSet(i+1) && dataSet(i) > mean_end_1){
          index_2(id2) = index_1(i)
          data_2(id2) = data_1(i)
          id2 = id2 + 1
        }
      }
    }
    if(data_1(data_1.length-1) > data_1(data_1.length) && data_1(data_1.length) > data_mean_1){
      index_2(id2) = data_1.length - 1
      data_2(id2) = data_1(data_1.length-1)
    }
    return calInterval(index_2)
  }

  def calInterval(timeArr:ArrayBuffer[Int]):ArrayBuffer[Double]={
    var intervalArr = new ArrayBuffer[Double]()
    var intervalArrFinal = new ArrayBuffer[Double]()
    var index=0
    for(i <- 0 to timeArr.length - 2){
      intervalArr(i) = (timeArr(i+1)-timeArr(i))*TIME_INTERVAL
      if(intervalArr(i) >= MIN && intervalArr(i) <= MAX){
        intervalArrFinal(index) = intervalArr(i)
        print("final:",intervalArrFinal(index))
        index = index + 1
      }
    }
    return intervalArrFinal
  }

  def calSD1AndSD2(interArrayBuffer: ArrayBuffer[Double]):(Double,Double)={
    var len =  interArrayBuffer.size
    println("array len:",len-2)
    //x,y数组
    var arrayX = new ArrayBuffer[Double]()
    var arrayY = new ArrayBuffer[Double]()
    var arrayX_Y = new ArrayBuffer[Double]()
    var arrayXY = new ArrayBuffer[Double]()
    arrayX = interArrayBuffer.dropRight(1)
    arrayY = interArrayBuffer.drop(1)
    for (i <- 0 to (len-2)){
      arrayX_Y(i) = arrayX(i) - arrayY(i)
      arrayXY(i) = arrayX(i) + arrayY(i)
    }
    val SD1 = calculateSD(arrayX_Y)
    val SD2 = calculateSD(arrayXY)
    println("SD1:",SD1)
    println("SD2:",SD2)
    return(SD1,SD2)
  }

  def calculateSD(array:ArrayBuffer[Double]):Double={
    //通过map和reduce方法得到(x-y)的和,(x-y)的平方和
    var result = array.map(a => (1,a,a*a)).reduce((a,b)=>(a._1 + b._1,a._2+b._2,a._3+b._3))
    var SD = Math.sqrt((result._3/result._1-result._2*result._2/result._1/result._1)/2)
    return SD
  }


  def main(args: Array[String]): Unit = {
    var masterUrl = "local[2]"
    if (args.length > 0) {
      masterUrl = args(0)
    }

    // Create a StreamingContext with the given master URL
    val conf = new SparkConf().setMaster(masterUrl).setAppName("PageViewStream")
    val ssc = new StreamingContext(conf, Seconds(5))

    // Kafka configurations
    //val topics = Set("PageViewStream")
    val topics = Set("user_events")
    //本地虚拟机ZK地址
    //val brokers = "hadoop1:9092,hadoop2:9092,hadoop3:9092"
    val brokers = "localhost:9092"
    val kafkaParams = Map[String, String](
      "metadata.broker.list" -> brokers,
      "serializer.class" -> "kafka.serializer.StringEncoder")

    // Create a direct stream
    val kafkaStream = KafkaUtils.createDirectStream[String, String, StringDecoder, StringDecoder](ssc, kafkaParams, topics)

    //获取event
    val events = kafkaStream.map(line => {
      JSONObject.fromObject(line._2)
    })

    events
      .map(x => (x.getString("uid"), x.getString("heartbeat")))
      .foreachRDD( rdd => {
        rdd.foreach( x => {
          handleArr(x._2.split(","))
        })
    })

    ssc.start()
    ssc.awaitTermination()

  }

  def handleArr(arr : Array[String]): Unit = {

//    val lines = events.map(x => (x.getString("uid"), x.getString("heartbeat")))
//
//    //val lines = events.map(x => (x.getString("heartbeat")))
//
//    val originData = new ArrayBuffer[Int]()
//    lines.foreachRDD(rdd=>{
//      rdd.foreach(x=>{
//        val temp:Array[String] = x._2.split(",")
//        for(i <- 0 until temp.size){
//          originData.append(temp(i).toInt)
//        }
//        println("originData的长度："+originData.size)
//      })
//
//    })

    val originData = new ArrayBuffer[Int]()
    //val temp:Array[String] = msg.getString("heartbeat").split(",")
    arr.foreach( x => originData.append(x.toInt))
    val intervalArray = getInterval(originData)
    println("intervalArray大小：",intervalArray.size)
    val SD1,SD2 = calSD1AndSD2(intervalArray)
    println("SD1--SD2:" + SD1,SD2)
  }




}

